## 라이브러리 설치

!pip install cmake
!pip install transformers
!pip install --upgrade pip
!pip install kiwipiepy
!pip install kiwipiepy transformers torch sentencepiece
!pip install scikit-learn

!pip install gradio

## 데이터 전처리

import pandas as pd

# 1. 엑셀 파일 읽어오기
excel_path1 = '/content/wellness_final.xlsx'  #동진
excel_path2 = '/content/7label.xlsx'

df1 = pd.read_excel(excel_path1)
df2 = pd.read_excel(excel_path2)

df1_selected = df1.iloc[1:19770, [0, 1]] #동진
df1_selected.columns = ['keyword', 'text']

df2_selected = df2.iloc[1:, [1, 0]] #혜란
df2_selected.columns = ['keyword', 'text']
df2_selected = df2_selected[df2_selected['keyword'].isin(['행복', '중립'])]

# 행 병합
df_merged = pd.concat([df1_selected, df2_selected], axis=0)

# 제외할 키워드 목록
exclude_keywords = ['충동', '낙 없음', '실망', '모욕감', '절박', '곤란']
# 제외할 키워드에 해당하는 행 제거
df_merged = df_merged[~df_merged['keyword'].isin(exclude_keywords)]

# NaN 값이 있는 행 제거
df_merged = df_merged.dropna()
# 키워드 값 출력
print("Keywords in df_merged:")
print(df_merged['keyword'].unique())

# 텍스트 열 지정
texts = df_merged['text'].tolist()

# 신조어 데이터셋 불러오기
df4 = pd.read_csv('./korean_slang.csv')
new_words_dict = pd.Series(df4.뜻풀이.values, index=df4.신조어).to_dict()

### 감정분석용 전처리

df3 = pd.read_excel(excel_path2, usecols=[1, 0], names=['text', 'label'])

# 레이블을 숫자로 매핑!pip install scikit-learn
label_mapping = {
    '행복': 0,
    '중립': 1,
    '슬픔': 2,
    '공포': 3,
    '혐오': 4,
    '분노': 5,
    '놀람': 6
}

# 'label' 열을 숫자로 매핑
df3['label'] = df3['label'].map(label_mapping)

# NaN 값이 있는 행 제거
df3 = df3.dropna(subset=['text'])
df3 = df3.dropna(subset=['label'])

df3['label'] = df3['label'].astype(int)

# 텍스트와 레이블을 리스트로 변환
train_texts = df3['text'][1:].tolist()
train_texts = [str(text) for text in train_texts]
train_labels = df3['label'][1:].tolist()

# 키워드 병합 규칙 적용
df_merged['keyword'] = df_merged['keyword'].replace({
    '수면장애': '불면', '잠이안옴': '불면', '잠드는데 어려움': '불면',	'자다깸': '불면',	'자도피로안풀림': '불면',	'수면시간감소': '불면',	'잠설침': '불면',	'얕게잠': '불면',	'몽롱': '불면',	'조각잠': '불면',	'비몽사몽': '불면',	'피곤': '불면',
    '눈물': '슬픔', '울음': '슬픔',
    '식욕부진': '식욕감소',	'체중감소': '식욕감소',	'입맛감소': '식욕감소',	'살빠짐': '식욕감소',	'식사량감소': '식욕감소',
    '위축':'자존감감소',	'자신감감소':'자존감감소',	'소심':'자존감감소',	'하찮음':'자존감감소',	'못남':'자존감감소',	'한심':'자존감감소',	'가치 없음':'자존감감소',	'나약':'자존감감소',
    '패배자':'패배감',	'포기':'패배감',
    '비웃음':'피해의식',	'업신여김':'피해의식',	'눈초리':'피해의식',	'냉소':'피해의식',	'감시':'피해의식',	'해코지':'피해의식',	'손가락질':'피해의식',	'째려보다':'피해의식',
    '죄인':'죄책감',	'잘못':'죄책감',	'질책':'죄책감',	'자책':'죄책감',
    '안타까움':'연민',
    '허무함': '허무', '허망': '허무',	'공허': '허무',	'허탈': '허무', '허망함':'허무','허무  ':'허무',
    '희망없음':'절망감',	'낭떠러지 끝에 있는 느낌':'절망감',
    '후회함': '후회',
    '종잡을수없음':'혼란',	'우유부단':'혼란',	'결단력없음':'혼란',
    '쓸쓸함': '외로움', '적적함': '외로움',	'겉돌다': '외로움',
    '무의미':'무의미함',
    '고독감':'외톨이',
    '욱함':'화',
    '감정기복':'조울',
    '증오':'분노',
    '자괴감':'괴로움',	'괴롭다':'괴로움',	'고통':'괴로움',
    '신경날카로움':'예민',	'짜증':'예민',	'신경질':'예민',
    '메슥거림':'소화불량',
    '폭식':'체중증가',	'살찌다':'체중증가',	'과체중':'체중증가',	'과식증':'체중증가',
    '섭섭함': '서운함',
    '기분우울': '침울',	'울적함':'침울', '상쾌하지않음':'침울',	'기분처짐':'침울',
    '흥미상실':'의욕감소', '무의욕':'의욕감소',	'의욕없음':'의욕감소',	'흥미감소':'의욕감소',	'즐거움감소':'의욕감소',	'나른한':'의욕감소',	'성욕감소':'의욕감소',
    '쇠약':'무기력',	'힘없음':'무기력',	'탈력감':'무기력',	'졸림':'무기력',	'힘빠짐':'무기력',	'많이잠':'무기력',	'찌뿌둥함':'무기력',
    '안절부절못함':'불안',	'조마조마함':'불안',	'가만히못있음':'불안',	'떨림':'불안',	'걱정':'불안',	'정서불안(불안감)':'불안',	'불안정':'불안',	'긴장':'불안',	'압박감':'불안',
    '귀찮음':'늘어짐',	'무거움':'늘어짐',	'느릿느릿':'늘어짐',	'처짐':'늘어짐',	'누움':'늘어짐',	'둔화':'늘어짐',	'느긋':'늘어짐',
    '숨참':'답답',	'앞이 깜깜함':'답답',	'막막함':'답답',
    '집중력저하':'사고력',	'책이안읽힘':'사고력',	'tv집중안됨':'사고력',
    '좌절감':'좌절'
})

import gradio as gr
import torch
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, T5ForConditionalGeneration, T5Tokenizer, MarianMTModel, MarianTokenizer, BartTokenizer, BartForConditionalGeneration
from sentence_transformers import SentenceTransformer, util
import pandas as pd
from kiwipiepy import Kiwi
import re

# 모델 미리 로드 (한 번만 로드하고 이후에는 로드된 모델 사용)
print("Loading models...")

# 감정 분석 파이프라인 모델 로드
tokenizer = AutoTokenizer.from_pretrained("beomi/KcELECTRA-base-v2022")
model = AutoModelForSequenceClassification.from_pretrained("beomi/KcELECTRA-base-v2022", num_labels=7)
sentiment_analyzer = pipeline("text-classification", model=model, tokenizer=tokenizer)

# SBERT 모델 로드
model2 = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')
embeddings = model2.encode(texts, convert_to_tensor=True)

# 번역 및 이모지 변환 모델 로드
ko_to_en_model = MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-ko-en')
ko_to_en_tokenizer = MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-ko-en')
emoji_tokenizer = BartTokenizer.from_pretrained("KomeijiForce/bart-large-emojilm")
emoji_generator = BartForConditionalGeneration.from_pretrained("KomeijiForce/bart-large-emojilm")

# 맞춤법 교정 모델 로드
corrector_model = T5ForConditionalGeneration.from_pretrained("j5ng/et5-typos-corrector")
corrector_tokenizer = T5Tokenizer.from_pretrained("j5ng/et5-typos-corrector")

kiwi = Kiwi(num_workers=0, model_path=None, load_default_dict=True, integrate_allomorph=True, model_type='knlm', typos=None, typo_cost_threshold=2.5)
print("Models loaded.")

## 전처리

### 문장 분리

def split(a):
  sentences = kiwi.split_into_sents(a)
  textArray = [sentence.text for sentence in sentences]
  return textArray

### 신조어 치환

def correct_new_words_before_tokenizing(sentence):
    # 신조어 사전에 있는 단어를 치환
    for new_word, standard_word in new_words_dict.items():
        if new_word in sentence:
            sentence = sentence.replace(new_word, standard_word)
    return sentence

### 맞춤법 교정

# 디바이스 설정 (T4 GPU 사용)
device = "cpu"

# 모델 로드 시 GPU로 이동
corrector_model = corrector_model.to(device)
model = model.to(device)
model2 = model2.to(device)
ko_to_en_model = ko_to_en_model.to(device)
emoji_generator = emoji_generator.to(device)

# 각 문장에 대해 맞춤법 교정 수행
def correct_sentence(sentence):
    # 입력 문장 인코딩
    input_encoding = corrector_tokenizer(sentence, return_tensors="pt").to(device)
    input_ids = input_encoding.input_ids
    attention_mask = input_encoding.attention_mask

    # T5 모델 출력 생성
    output_encoding = corrector_model.generate(
        input_ids=input_ids,
        attention_mask=attention_mask,
        max_length=128,
        num_beams=5,
        early_stopping=True,
    )

    # 출력 문장 디코딩
    output_text = corrector_tokenizer.decode(output_encoding[0], skip_special_tokens=True)

    # 교정된 문장 추가
    return output_text

### 번역

# 한국어-영어 번역 함수
def translate_ko_to_en(text):
    tokens = ko_to_en_tokenizer(text, return_tensors="pt", padding=True).to(device)
    translation = ko_to_en_model.generate(**tokens)
    return ko_to_en_tokenizer.decode(translation[0], skip_special_tokens=True)

## Text2Emoji

# 감정 분석 및 이모지 변환 함수
def emoji_convert(text):
    inputs = emoji_tokenizer(text, return_tensors="pt").to(device)
    generated_ids = emoji_generator.generate(inputs["input_ids"], num_beams=4, do_sample=True, max_length=100)
    emoji_text = emoji_tokenizer.decode(generated_ids[0], skip_special_tokens=True).replace(" ", "")
    return emoji_text

### 감정분석

from transformers import Trainer, TrainingArguments
from sklearn.model_selection import train_test_split

# 학습 데이터와 검증 데이터로 분리 (80% 학습, 20% 검증)
train_texts, eval_texts, train_labels, eval_labels = train_test_split(train_texts, train_labels, test_size=0.2, random_state=42)

# 학습 데이터 토크나이징
train_encodings = tokenizer(train_texts, truncation=True, padding=True, return_tensors="pt")
eval_encodings = tokenizer(eval_texts, truncation=True, padding=True, return_tensors="pt")

class SentimentDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)
        return item

    def __len__(self):
        return len(self.labels)

train_dataset = SentimentDataset(train_encodings, train_labels)
eval_dataset = SentimentDataset(eval_encodings, eval_labels)

# 학습 설정
training_args = TrainingArguments(
    output_dir='./results',
    num_train_epochs=3,
    per_device_train_batch_size=64,
    per_device_eval_batch_size=32,
    warmup_steps=500,
    weight_decay=0.01,
    logging_dir='./logs',
    logging_steps=10,
    evaluation_strategy="steps",
    save_total_limit=2,
    load_best_model_at_end=True,
    save_steps=500,
    eval_steps=500,
    report_to=["none"]
)

# Trainer 객체 생성
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    tokenizer=tokenizer
)

# 학습 시작
trainer.train()

from transformers import pipeline

def analyze_emotion(text):
    sentiment_analyzer = pipeline("text-classification", model=model, tokenizer=tokenizer)

    result = sentiment_analyzer(text)[0]

    label_mapping = {
        'LABEL_0': '행복',
        'LABEL_1': '중립',
        'LABEL_2': '슬픔',
        'LABEL_3': '공포',
        'LABEL_4': '혐오',
        'LABEL_5': '분노',
        'LABEL_6': '놀람'
    }

    label = result['label']
    emotion = label_mapping.get(label, "알 수 없음")  # 레이블을 감정 이름으로 변환

    if emotion in ['슬픔', '공포', '혐오', '분노', '중립']:
        return True
    else:
        return False

### 레드플래그

# 키워드별 평균 벡터 계산 (중립과 행복 제외)
keywords = [keyword for keyword in df_merged['keyword'].unique() if keyword not in ['행복', '중립']]
keyword_avg_embeddings = {}
for keyword in keywords:
    keyword_texts = df_merged[df_merged['keyword'] == keyword]['text'].tolist()
    if len(keyword_texts) > 0:
        keyword_embeddings = model2.encode(keyword_texts, convert_to_tensor=True)
        keyword_avg_embeddings[keyword] = torch.mean(keyword_embeddings, dim=0, keepdim=True)

import random
# 중립 텍스트에서 무작위로 50개 샘플링
neutral_texts = df_merged[df_merged['keyword'] == '중립']['text'].tolist()
neutral_sample_texts = random.sample(neutral_texts, min(40, len(neutral_texts)))
neutral_embeddings = model2.encode(neutral_sample_texts, convert_to_tensor=True)

# 행복 텍스트에서 무작위로 50개 샘플링
happy_texts = df_merged[df_merged['keyword'] == '행복']['text'].tolist()
happy_sample_texts = random.sample(happy_texts, min(40, len(happy_texts)))
happy_embeddings = model2.encode(happy_sample_texts, convert_to_tensor=True)

# 중립과 행복 벡터 추가
keyword_avg_embeddings['중립'] = neutral_embeddings
keyword_avg_embeddings['행복'] = happy_embeddings

# 가장 유사한 키워드 반환 함수 정의
def get_most_similar_keyword(target_sentence, model2, keyword_avg_embeddings):
    target_embedding = model2.encode(target_sentence, convert_to_tensor=True).to(device)
    keyword_similarities = {}

    for keyword, avg_embedding in keyword_avg_embeddings.items():
        if avg_embedding.dim() > 1:  # 중립과 행복 벡터는 여러 개임, 평균 벡터 계산
            avg_embedding = torch.mean(avg_embedding, dim=0).to(device)
        else:
            avg_embedding = avg_embedding.to(device)
        similarity = util.pytorch_cos_sim(target_embedding, avg_embedding).item()
        keyword_similarities[keyword] = similarity

# 가장 유사도가 높은 키워드 반환
    most_similar_keyword = max(keyword_similarities, key=keyword_similarities.get)
    return most_similar_keyword, keyword_similarities[most_similar_keyword]

def emotionize(a):
  if a in ["죽고싶음", "죽이고싶음", "희망없음", "앞이 깜깜함", "가치 없음", "낭떠러지 끝에 있는 느낌"]:
    return 1000
  elif a in [
    "자존감감소", "패배감", "하찮음", "괴로움", "못남", "절망감", "포기",
    "좌절감", "절박",
    "피해의식", "비웃음", "눈초리", "냉소", "감시", "기분우울", "슬픔", "눈물", "울음", "죄책감", "자괴감", "비참", "서러움",
    "고독감", "막막함", "고통"
]:
    return 2
  elif a in [
    "우울", "침울", "멍함", "서운함", "섭섭함", "불만", "슬럼프", "나른함", "힘없음", "처짐", "힘빠짐", "찌뿌둥함", "많이잠", "느릿느릿함",
    "무의욕", "수면장애", "집중력감소", "의욕없음", "잠이안옴", "무기력", "의욕감소", "불면", "흥미상실", "식욕부진",
    "공허", "낙 없음", "즐거움감소", "답답함", "기분처짐", "짜증", "안절부절못함", "조마조마함", "혼란", "허무함", "허탈",
    "소심", "자신감감소", "위축", "우유부단", "결단력없음",
    "속상함", "후회", "후회함", "억울함",
    "외로움", "쓸쓸함"
]:
    return 1
  else:
    return 0

# risk의 종류에 따라 다른 메시지 출력하는 함수
import random

comforting_messages = [
    "오늘 힘들었다면 잠시 쉬어도 괜찮아요. 당신은 소중한 사람이에요. 🌟",
    "지금은 어렵게 느껴질 수 있지만, 분명히 더 나아질 거예요. 당신의 마음을 믿어요. 💖",
    "힘들 땐 혼자 짊어지지 말고 주변에 도움을 요청하세요. 당신은 혼자가 아니에요. 🤗",
    "스스로를 다독여 주세요. 당신은 지금도 충분히 잘하고 있어요. 🌈",
    "작은 한 걸음도 소중해요. 천천히, 꾸준히 걸어가요. 🌱",
    "오늘도 최선을 다한 당신에게 따뜻한 응원을 보냅니다. ☀️",
    "때로는 쉬어가는 것도 필요한 시간이랍니다. 괜찮아요. 🌼",
    "작은 기쁨 하나씩 찾아보며 스스로에게 웃음을 선물해 주세요. 😊",
    "어두운 길도 언젠가 환히 비춰질 거예요. 조금만 더 힘내봐요. 🌙",
    "당신의 하루는 누군가에게 큰 위안이 되고 있을 거예요. 💌",
    "지금도 당신은 충분히 특별하고 소중한 존재예요. 💎",
    "매일 작은 변화가 모여 큰 성장을 이룬답니다. 자신을 믿어주세요. 🌻",
    "당신은 존재만으로도 많은 사람에게 기쁨이 되고 있어요. ❤️",
    "마음의 짐이 무거울 땐 깊게 숨을 쉬어보세요. 괜찮아질 거예요. 🍃",
    "오늘 당신이 해낸 모든 일들, 다 멋진 걸음이에요. 자랑스러워요. 🏞️"
]
cautionary_messages = [
    "혹시 너무 많은 스트레스를 받고 있는 건 아닌가요? 잠시 멈추고 자신을 돌아보세요. ⚠️",
    "최근 감정이 무겁다면 믿을 수 있는 사람과 대화해보는 건 어떨까요? 🛑",
    "힘든 상황에서 무리하려 하지 말고 스스로를 보호하는 선택을 해보세요. 🕊️",
    "이 감정이 오래 지속된다면 전문가의 도움을 받는 것도 좋은 방법이에요. 🩺",
    "어떤 결정을 내리기 전, 감정에 휩쓸리지 않고 신중하게 생각해보세요. 🛡️",
    "혹시 스스로를 너무 몰아붙이고 있진 않은가요? 자신에게 휴식을 허락해 주세요. 🚦",
    "감정이 격해질 땐 잠시 멈추고 자신을 돌아보는 시간을 가져보세요. ⏳",
    "마음이 지쳤다면 도움을 요청해도 괜찮아요. 당신은 소중하니까요. 🫂",
    "스스로 감당하기 힘든 상황이라면 혼자 끙끙 앓지 말고 주변에 알리세요. 📣",
    "힘든 순간에는 모든 걸 내려놓고 마음의 평화를 찾는 것이 필요할 수도 있어요. 🕊️",
    "가끔은 자신의 감정을 기록해보세요. 이를 통해 마음을 정리할 수 있을 거예요. ✍️",
    "최근 힘든 일이 많았다면 충분히 쉬고 스스로를 위로하는 시간을 가져보세요. 🌌",
    "너무 깊은 고민에 빠지기보단 믿을 수 있는 사람과 함께 해결해보세요. 🤝",
    "당신의 감정은 소중합니다. 이를 무시하거나 억누르지 않아도 돼요. 🌷",
    "스스로를 돌보는 것이야말로 진정한 용기입니다. 당신을 응원해요. 🛡️"
]



def showMessage(risk):
  risk=float(risk)
  if (2/3)> risk >= (1/3):
    return(comforting_messages[random.randint(0, len(comforting_messages) - 1)])
  elif risk >= (2/3):
    return(cautionary_messages[random.randint(0, len(cautionary_messages) - 1)]+"\n"+"\n" + "지금 힘든 상황에 처해 있거나 감정적으로 어려움을 겪고 계신다면,"+"\n"+"전문적인 도움을 받는 것이 중요합니다." + "\n" + "한국 정신건강 상담전화 1577-0199")
  else :
    return ""

## 최종

# 전체 함수 실행
def correct(a):
  korean_text = a
  slang_korean= correct_new_words_before_tokenizing(korean_text)
  correct_korean=correct_sentence(slang_korean)
  return correct_korean

def text2emoji(a):
  translated_text = translate_ko_to_en(a)
  emoji_text = emoji_convert(translated_text)
  return emoji_text
def emotion_texting(a):
  most_similar_keyword, similarity = get_most_similar_keyword(a, model2, keyword_avg_embeddings)
  return most_similar_keyword

def final(user_input):
    count = 0
    emotion = 0
    analyze= 0
    diary = ""
    emoji = ""

    textArray = split(user_input)

    for i in textArray:
        count += 1
        correct_korean = correct(i)
        emoji = text2emoji(correct_korean)
        analyze=analyze_emotion(i)
        redscore = emotion_texting(i)
        diary = diary + i + emoji + "\t"
        if analyze == True:
          emotion += emotionize(redscore)
        else:
          emotion+=0
    output_message = showMessage(emotion / count)
    output = diary + '\n'+'\n'+'\n'+ output_message
    return output

# Gradio 인터페이스 정의
def run_final(user_input):
    return final(user_input)

css = """
/* 전체 컨테이너 수직 정렬 */
.gradio-container {
    display: flex;
    justify-content: center;
    align-items: center;
    width: 900px;
    height: 100vh; /* 전체 화면에 수직 정렬 */
    padding-top: 200px;

    gap: 20px; /* 요소 간 간격 */
    background-color: #FFF8dc;
}

/* 입력과 출력 박스를 가로로 배치 */
.gradio-input-output {
    width: 300px;
    gap: 20px; /* 요소 간 간격 */
}

.gap.svelte-vt1mxs {
  width: 900px;
  padding-top: 12vh;
}

.gradio-container-5-6-0 .prose * {
  width: 900px;
  text-align: center;
}



/* description 스타일 */
#interface-description {
    width: 900px;
    text-align: center;
    margin-bottom: 20px;
    font-size: 2rem;
}

.gradio-container.gradio-container-5-6-0 .contain button {
  height: 60px;
  font-size: 1.5rem;
}

/* input & output container */

div.svelte-633qhp .block {
  background-color: #fffaf0;
}

/* input label */
span.svelte-1gfkn6j {
  font-size: 1.2rem;
  font-weight: 600;
}

/* 버튼 스타일 */
button {
    padding: 10px 20px;
    background-color: #ff7f50;
    color: white;
    border: none;
    border-radius: 5px;
    cursor: pointer;
}

button:hover {
    background-color: #ff6347;
}

/* Emotify 🤩 */
h1 {
  font-size : 3rem;
}

/*  텍스트에 감정을 더하다😉 */
h3 {
  font-size : 2rem;
}
"""

title = "Emotify 🤩"  # 페이지 제목 설정

# Gradio Blocks를 사용하여 UI 구성
with gr.Blocks(css=css, title=title) as demo:
    gr.Markdown("# Emotify🤩 \n ### 텍스트에 감정을 더하다😉")

    # 입력과 출력 박스를 가로로 배치
    with gr.Row(elem_id="gradio-input-output"):
        input_box = gr.Textbox(lines=20, placeholder="감정을 표현해 보세요.", label="감정 표현하기")
        output_box = gr.Textbox(lines=20, label="감정 불어넣기")

    # 버튼 추가
    submit_button = gr.Button("감정 불어넣기😙")  # 버튼 텍스트 설정

    # 버튼 클릭 이벤트 연결
    submit_button.click(fn=final, inputs=input_box, outputs=output_box)

# Gradio 실행
demo.launch(share=True)
